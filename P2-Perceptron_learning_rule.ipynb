{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def calculate_perceptron(self, inputs):\n",
    "        list_outputs = []\n",
    "        if len(inputs) == len(self.weights):\n",
    "            for x, weight in zip(inputs, self.weights):\n",
    "                list_outputs.append(x*weight)\n",
    "        else:\n",
    "            raise ValueError(\"The list of inputs and weights must have the same length\")\n",
    "         \n",
    "        output = sum(list_outputs) + self.bias \n",
    "        return self.step_function(output)\n",
    "    \n",
    "    def step_function(self, output):\n",
    "        if output >= 0:\n",
    "            return_value = 1\n",
    "        else:\n",
    "            return_value = 0\n",
    "        return return_value\n",
    "    \n",
    "    def update(self, input_binair, target):\n",
    "        learning_rate = 0.1\n",
    "                \n",
    "        output = self.calculate_perceptron(input_binair)\n",
    "            \n",
    "        error = target - output\n",
    "        \n",
    "        for index in range(len(self.weights)):\n",
    "            self.weights[index]+= learning_rate * error * input_binair[index]\n",
    "        \n",
    "        self.bias += learning_rate * error \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Weights are {self.weights} and bias is {self.bias}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron_layer:\n",
    "    def __init__(self, perceptrons):\n",
    "        self.perceptrons = perceptrons\n",
    "    \n",
    "    def calculate_layer(self, inputs):\n",
    "        output = []\n",
    "        for perceptron in self.perceptrons:\n",
    "            output.append(perceptron.calculate_perceptron(inputs))\n",
    "        return output\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'The layer consist out of these perceptrons: {self.perceptrons}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron_network:\n",
    "    def __init__(self, perceptron_layers):\n",
    "        self.perceptron_layers = perceptron_layers\n",
    "    \n",
    "    def feed_forward(self, inputs):\n",
    "        for perceptron_layer in self.perceptron_layers:\n",
    "            inputs = perceptron_layer.calculate_layer(inputs)\n",
    "        return inputs\n",
    "    \n",
    "        def __str__(self):\n",
    "            return f'The network consist out of these perceptron_layers: {self.perceptron_layers}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_X1 = Perceptron([1, 0], -0.5)\n",
    "# Fill up the Neuron weights with zero's equal to that many values you want to put into the Neural Network.\n",
    "# Warning! When you give weights 0 and 1 to neuron_X2 the value will set to only the value of x2. If not this neuron will get the value of x1!\n",
    "hidden_layer_X2 = Perceptron([0, 1], -0.5)\n",
    "\n",
    "hidden_perceptron_NAND = Perceptron([-0.2, -0.2], 0.3)\n",
    "hidden_perceptron_OR = Perceptron([1, 1], -1)\n",
    "hidden_perceptron_AND = Perceptron([1, 1], -1.5)\n",
    "\n",
    "output_perceptron_sum = Perceptron([1, 1, 0], -1.5) # XOR port\n",
    "output_perceptron_carry = Perceptron([0, 0, 1], -0.5) # AND port\n",
    "\n",
    "input_perceptron_layer = Perceptron_layer([hidden_layer_X1, hidden_layer_X2])\n",
    "hidden_perceptron_layer = Perceptron_layer([hidden_perceptron_NAND, hidden_perceptron_OR, hidden_perceptron_AND])\n",
    "output_perceptron_layer = Perceptron_layer([output_perceptron_carry, output_perceptron_sum])\n",
    "\n",
    "neural_network_perceptrons = Perceptron_network([input_perceptron_layer, hidden_perceptron_layer, output_perceptron_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[0,0],[0,1],[1,0],[1,1]]\n",
    "\n",
    "print('x1, x2, carry, sum')\n",
    "for input_x in inputs:\n",
    "    print(input_x, '   ', neural_network_perceptrons.feed_forward(input_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_error(target_list, output_list):\n",
    "    return np.mean([abs(a)-abs(b)**2 for a,b in zip(target_list, output_list)])\n",
    "\n",
    "def train_perceptron(perceptron, posible_input):\n",
    "    \"\"\"\n",
    "    Put in like this [[[0, 0], 0],\n",
    "                      [[0, 1], 0],\n",
    "                      [[1, 0], 0],\n",
    "                      [[1, 1], 1]]\n",
    "    \"\"\"\n",
    "    outcome = 0\n",
    "    print('x1 x2 target output')\n",
    "    while outcome != 4:\n",
    "        outcome = 0\n",
    "        li = []\n",
    "        for answer in posible_input:\n",
    "            \n",
    "            output = perceptron.calculate_perceptron(answer[0])\n",
    "            \n",
    "            perceptron.update(answer[0], answer[1])\n",
    "            print(answer[0], answer[1], '    ', output)\n",
    "            li.append(output)\n",
    "            if output == answer[1]:\n",
    "                outcome+=1\n",
    "        error = MSE_error([x[1] for x in posible_input], li)\n",
    "        print('error = ', error)\n",
    "        if error == 0 and outcome == 4: \n",
    "            print('perceptron trained!')\n",
    "            print('the weights are', perceptron.weights)\n",
    "            print('the bias is', perceptron.bias)\n",
    "        else:\n",
    "            outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_train_AND = Perceptron([0.1, 0.1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perceptron(perceptron_train_AND,\n",
    "                 [[[0, 0], 0],\n",
    "                  [[0, 1], 0],\n",
    "                  [[1, 0], 0],\n",
    "                  [[1, 1], 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_train_NAND = Perceptron([0.1, 0.1], 0.1)\n",
    "perceptron_train_OR = Perceptron([0.1, 0.1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perceptron(perceptron_train_NAND,\n",
    "                 [[[0, 0], 1],\n",
    "                  [[0, 1], 1],\n",
    "                  [[1, 0], 1],\n",
    "                  [[1, 1], 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perceptron(perceptron_train_OR,\n",
    "                 [[[0, 0], 0],\n",
    "                  [[0, 1], 1],\n",
    "                  [[1, 0], 1],\n",
    "                  [[1, 1], 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR_input1 = Perceptron([1, 0], -0.5)\n",
    "# Fill up the Neuron weights with zero's equal to that many values you want to put into the Neural Network.\n",
    "# Warning! When you give weights 0 and 1 to neuron_X2 the value will set to only the value of x2. If not this neuron will get the value of x1!\n",
    "XOR_input2 = Perceptron([0, 1], -0.5)\n",
    "\n",
    "input_trained_perceptron_layer = Perceptron_layer([XOR_input1, XOR_input2])\n",
    "hidden_trained_perceptron_layer = Perceptron_layer([perceptron_train_NAND, perceptron_train_OR])\n",
    "output_trained_perceptron_layer = Perceptron_layer([perceptron_train_AND])\n",
    "\n",
    "neural_network_trained_perceptrons = Perceptron_network([input_trained_perceptron_layer, hidden_trained_perceptron_layer, output_trained_perceptron_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[0,0],[0,1],[1,0],[1,1]]\n",
    "\n",
    "print('x1, x2, output')\n",
    "for input_x in inputs:\n",
    "    print(input_x, '   ', neural_network_trained_perceptrons.feed_forward(input_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(a=1715354)\n",
    "random_numbers = random.getstate()[1]\n",
    "random_numbers = ''.join(str(x) for x in random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_perceptron_input1 = Perceptron([1, 0, 0 ,0], 0)\n",
    "iris_perceptron_input2 = Perceptron([0, 1, 0 ,0], 0)\n",
    "iris_perceptron_input3 = Perceptron([0, 0, 1 ,0], 0)\n",
    "iris_perceptron_input4 = Perceptron([0, 0, 0 ,1], 0)\n",
    "\n",
    "perceptron_setosa = Perceptron([int(random_numbers[0]), int(random_numbers[1]), int(random_numbers[2]), int(random_numbers[3])], int(random_numbers[4]))\n",
    "perceptron_versicolour = Perceptron([int(random_numbers[5]), int(random_numbers[6]), int(random_numbers[7]), int(random_numbers[8])], int(random_numbers[9]))\n",
    "perceptron_verginica = Perceptron([int(random_numbers[10]), int(random_numbers[11]), int(random_numbers[12]), int(random_numbers[13])], int(random_numbers[14]))\n",
    "\n",
    "flower_perceptron_layer_in = Perceptron_layer([iris_perceptron_input1, iris_perceptron_input2, iris_perceptron_input3, iris_perceptron_input4])\n",
    "flower_perceptron_layer_out = Perceptron_layer([perceptron_setosa, perceptron_versicolour, perceptron_verginica])\n",
    "\n",
    "neural_network_flower_perceptrons = Perceptron_network([flower_perceptron_layer_in, flower_perceptron_layer_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_target = [[data, target] for data, target in zip(iris['data'][0:10], iris['target'][0:10])] \n",
    "train_perceptron(perceptron_setosa, data_and_target)\n",
    "\n",
    "data_and_target = [[data, target] for data, target in zip(iris['data'][60:70], iris['target'][60:70])] \n",
    "train_perceptron(perceptron_versicolour, data_and_target)\n",
    "\n",
    "data_and_target = [[data, target] for data, target in zip(iris['data'][110:120], iris['target'][110:120])] \n",
    "train_perceptron(perceptron_verginica, data_and_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[0,0,1],[0,1,0],[1,0,0]]\n",
    "\n",
    "print('x1, x2, x3, x4, output')\n",
    "for input_x in inputs:\n",
    "    print(input_x, '   ', neural_network_flower_perceptrons.feed_forward(input_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit6aefb534615b451c8b9f779fc82cec76"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
